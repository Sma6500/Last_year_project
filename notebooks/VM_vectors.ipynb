{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdedcb77-dd09-480a-b282-a5dec18f0599",
   "metadata": {},
   "source": [
    "### VXM with vector\n",
    "<br/>\n",
    "\n",
    "Test notebook to transform vxm network to get a vectorize inputs.\n",
    "\n",
    "#### Add only a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab9db67-b0fc-455f-a6f3-ce50d1540ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys\n",
    "\n",
    "# third party imports\n",
    "import numpy as np\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03547a98-be47-4b6c-9f2f-344e1004c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class layer_vxm(nn.Module):  \n",
    "\n",
    "    def __init__(self):\n",
    "        super(layer_vxm, self).__init__()        \n",
    "        self.conv1 = nn.Sequential(nn.Conv3d(in_channels=6, \n",
    "                                             out_channels=2,            \n",
    "                                             kernel_size=3,              \n",
    "                                             stride=1),                      \n",
    "                                    nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x    \n",
    "    \n",
    "net=layer_vxm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ed0500-8d45-4ad0-bb8f-17a57d873161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "layer_vxm(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv3d(3, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device '+str(device))\n",
    "net.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "856753aa-4525-4c61-ba6b-5d938ba74b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.rand((1,3,200,192,148))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd4dd65-82a0-462e-857a-bd3c6c478c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=net(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e8aa0b-23fc-497f-a4a8-c1bfafd3730b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 198, 190, 146])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bc68b8-a766-4a12-ad56-3eef36193291",
   "metadata": {},
   "source": [
    "#### Change UNET Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09b906cc-abac-47f5-a7cb-9bc4d7f6e93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (main): Conv3d(6, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (main): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (main): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (main): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (main): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (main): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (main): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (main): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (remaining): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (main): Conv3d(48, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (activation): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (main): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (activation): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (main): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (activation): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.environ['VXM_BACKEND'] = 'pytorch'\n",
    "import voxelmorph as vxm\n",
    "test=vxm.networks.Unet(inshape=(224,160,192), \n",
    "                       infeats=6,\n",
    "                        nb_features=[[16, 32, 32, 32],[32, 32, 32, 32, 32, 16, 16]]\n",
    "                        )\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e314a96-3ff3-4905-8d51-1c443ebde28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "from .. import default_unet_features\n",
    "from . import layers\n",
    "from .modelio import LoadableModel, store_config_args\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    \"\"\"\n",
    "    A unet architecture. Layer features can be specified directly as a list of encoder and decoder\n",
    "    features or as a single integer along with a number of unet levels. The default network features\n",
    "    per layer (when no options are specified) are:\n",
    "        encoder: [16, 32, 32, 32]\n",
    "        decoder: [32, 32, 32, 32, 32, 16, 16]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 inshape=None,\n",
    "                 infeats=None,\n",
    "                 nb_features=None,\n",
    "                 nb_levels=None,\n",
    "                 max_pool=2,\n",
    "                 feat_mult=1,\n",
    "                 nb_conv_per_level=1,\n",
    "                 half_res=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            inshape: Input shape. e.g. (192, 192, 192)\n",
    "            infeats: Number of input features.\n",
    "            nb_features: Unet convolutional features. Can be specified via a list of lists with\n",
    "                the form [[encoder feats], [decoder feats]], or as a single integer. \n",
    "                If None (default), the unet features are defined by the default config described in \n",
    "                the class documentation.\n",
    "            nb_levels: Number of levels in unet. Only used when nb_features is an integer. \n",
    "                Default is None.\n",
    "            feat_mult: Per-level feature multiplier. Only used when nb_features is an integer. \n",
    "                Default is 1.\n",
    "            nb_conv_per_level: Number of convolutions per unet level. Default is 1.\n",
    "            half_res: Skip the last decoder upsampling. Default is False.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # ensure correct dimensionality\n",
    "        ndims = len(inshape)\n",
    "        assert ndims in [1, 2, 3], 'ndims should be one of 1, 2, or 3. found: %d' % ndims\n",
    "\n",
    "        # cache some parameters\n",
    "        self.half_res = half_res\n",
    "\n",
    "        # default encoder and decoder layer features if nothing provided\n",
    "        if nb_features is None:\n",
    "            nb_features = default_unet_features()\n",
    "\n",
    "        # build feature list automatically\n",
    "        if isinstance(nb_features, int):\n",
    "            if nb_levels is None:\n",
    "                raise ValueError('must provide unet nb_levels if nb_features is an integer')\n",
    "            feats = np.round(nb_features * feat_mult ** np.arange(nb_levels)).astype(int)\n",
    "            nb_features = [\n",
    "                np.repeat(feats[:-1], nb_conv_per_level),\n",
    "                np.repeat(np.flip(feats), nb_conv_per_level)\n",
    "            ]\n",
    "        elif nb_levels is not None:\n",
    "            raise ValueError('cannot use nb_levels if nb_features is not an integer')\n",
    "\n",
    "        # extract any surplus (full resolution) decoder convolutions\n",
    "        enc_nf, dec_nf = nb_features\n",
    "        nb_dec_convs = len(enc_nf)\n",
    "        final_convs = dec_nf[nb_dec_convs:]\n",
    "        dec_nf = dec_nf[:nb_dec_convs]\n",
    "        self.nb_levels = int(nb_dec_convs / nb_conv_per_level) + 1\n",
    "\n",
    "        if isinstance(max_pool, int):\n",
    "            max_pool = [max_pool] * self.nb_levels\n",
    "\n",
    "        # cache downsampling / upsampling operations\n",
    "        MaxPooling = getattr(nn, 'MaxPool%dd' % ndims)\n",
    "        self.pooling = [MaxPooling(s) for s in max_pool]\n",
    "        self.upsampling = [nn.Upsample(scale_factor=s, mode='nearest') for s in max_pool]\n",
    "\n",
    "        # configure encoder (down-sampling path)\n",
    "        prev_nf = infeats\n",
    "        encoder_nfs = [prev_nf]\n",
    "        self.encoder = nn.ModuleList()\n",
    "        for level in range(self.nb_levels - 1):\n",
    "            convs = nn.ModuleList()\n",
    "            for conv in range(nb_conv_per_level):\n",
    "                nf = enc_nf[level * nb_conv_per_level + conv]\n",
    "                convs.append(ConvBlock(ndims, prev_nf, nf))\n",
    "                prev_nf = nf\n",
    "            self.encoder.append(convs)\n",
    "            encoder_nfs.append(prev_nf)\n",
    "\n",
    "        # configure decoder (up-sampling path)\n",
    "        encoder_nfs = np.flip(encoder_nfs)\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for level in range(self.nb_levels - 1):\n",
    "            convs = nn.ModuleList()\n",
    "            for conv in range(nb_conv_per_level):\n",
    "                nf = dec_nf[level * nb_conv_per_level + conv]\n",
    "                convs.append(ConvBlock(ndims, prev_nf, nf))\n",
    "                prev_nf = nf\n",
    "            self.decoder.append(convs)\n",
    "            if not half_res or level < (self.nb_levels - 2):\n",
    "                prev_nf += encoder_nfs[level]\n",
    "\n",
    "        # now we take care of any remaining convolutions\n",
    "        self.remaining = nn.ModuleList()\n",
    "        for num, nf in enumerate(final_convs):\n",
    "            self.remaining.append(ConvBlock(ndims, prev_nf, nf))\n",
    "            prev_nf = nf\n",
    "\n",
    "        # cache final number of features\n",
    "        self.final_nf = prev_nf\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # encoder forward pass\n",
    "        x_history = [x]\n",
    "        for level, convs in enumerate(self.encoder):\n",
    "            for conv in convs:\n",
    "                x = conv(x)\n",
    "            x_history.append(x)\n",
    "            x = self.pooling[level](x)\n",
    "\n",
    "        # decoder forward pass with upsampling and concatenation\n",
    "        for level, convs in enumerate(self.decoder):\n",
    "            for conv in convs:\n",
    "                x = conv(x)\n",
    "            if not self.half_res or level < (self.nb_levels - 2):\n",
    "                x = self.upsampling[level](x)\n",
    "                x = torch.cat([x, x_history.pop()], dim=1)\n",
    "\n",
    "        # remaining convs at full resolution\n",
    "        for conv in self.remaining:\n",
    "            x = conv(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfbf0cf-8851-48b6-8ac6-326027ab466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "from .. import default_unet_features\n",
    "from . import layers\n",
    "from .modelio import LoadableModel, store_config_args\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    \"\"\"\n",
    "    A unet architecture. Layer features can be specified directly as a list of encoder and decoder\n",
    "    features or as a single integer along with a number of unet levels. The default network features\n",
    "    per layer (when no options are specified) are:\n",
    "        encoder: [16, 32, 32, 32]\n",
    "        decoder: [32, 32, 32, 32, 32, 16, 16]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 inshape=None,\n",
    "                 infeats=None,\n",
    "                 nb_features=None,\n",
    "                 nb_levels=None,\n",
    "                 max_pool=2,\n",
    "                 feat_mult=1,\n",
    "                 nb_conv_per_level=1,\n",
    "                 half_res=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            inshape: Input shape. e.g. (192, 192, 192)\n",
    "            infeats: Number of input features.\n",
    "            nb_features: Unet convolutional features. Can be specified via a list of lists with\n",
    "                the form [[encoder feats], [decoder feats]], or as a single integer. \n",
    "                If None (default), the unet features are defined by the default config described in \n",
    "                the class documentation.\n",
    "            nb_levels: Number of levels in unet. Only used when nb_features is an integer. \n",
    "                Default is None.\n",
    "            feat_mult: Per-level feature multiplier. Only used when nb_features is an integer. \n",
    "                Default is 1.\n",
    "            nb_conv_per_level: Number of convolutions per unet level. Default is 1.\n",
    "            half_res: Skip the last decoder upsampling. Default is False.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # ensure correct dimensionality\n",
    "        ndims = len(inshape)\n",
    "        assert ndims in [1, 2, 3], 'ndims should be one of 1, 2, or 3. found: %d' % ndims\n",
    "\n",
    "        # cache some parameters\n",
    "        self.half_res = half_res\n",
    "\n",
    "        # default encoder and decoder layer features if nothing provided\n",
    "        if nb_features is None:\n",
    "            nb_features = default_unet_features()\n",
    "\n",
    "        # build feature list automatically\n",
    "        if isinstance(nb_features, int):\n",
    "            if nb_levels is None:\n",
    "                raise ValueError('must provide unet nb_levels if nb_features is an integer')\n",
    "            feats = np.round(nb_features * feat_mult ** np.arange(nb_levels)).astype(int)\n",
    "            nb_features = [\n",
    "                np.repeat(feats[:-1], nb_conv_per_level),\n",
    "                np.repeat(np.flip(feats), nb_conv_per_level)\n",
    "            ]\n",
    "        elif nb_levels is not None:\n",
    "            raise ValueError('cannot use nb_levels if nb_features is not an integer')\n",
    "\n",
    "        # extract any surplus (full resolution) decoder convolutions\n",
    "        enc_nf, dec_nf = nb_features\n",
    "        nb_dec_convs = len(enc_nf)\n",
    "        final_convs = dec_nf[nb_dec_convs:]\n",
    "        dec_nf = dec_nf[:nb_dec_convs]\n",
    "        self.nb_levels = int(nb_dec_convs / nb_conv_per_level) + 1\n",
    "\n",
    "        if isinstance(max_pool, int):\n",
    "            max_pool = [max_pool] * self.nb_levels\n",
    "\n",
    "        # cache downsampling / upsampling operations\n",
    "        MaxPooling = getattr(nn, 'MaxPool%dd' % ndims)\n",
    "        self.pooling = [MaxPooling(s) for s in max_pool]\n",
    "        self.upsampling = [nn.Upsample(scale_factor=s, mode='nearest') for s in max_pool]\n",
    "\n",
    "        # configure encoder (down-sampling path)\n",
    "        prev_nf = infeats\n",
    "        encoder_nfs = [prev_nf]\n",
    "        self.encoder = nn.ModuleList()\n",
    "        for level in range(self.nb_levels - 1):\n",
    "            convs = nn.ModuleList()\n",
    "            for conv in range(nb_conv_per_level):\n",
    "                nf = enc_nf[level * nb_conv_per_level + conv]\n",
    "                convs.append(ConvBlock(ndims, prev_nf, nf))\n",
    "                prev_nf = nf\n",
    "            self.encoder.append(convs)\n",
    "            encoder_nfs.append(prev_nf)\n",
    "\n",
    "        # configure decoder (up-sampling path)\n",
    "        encoder_nfs = np.flip(encoder_nfs)\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for level in range(self.nb_levels - 1):\n",
    "            convs = nn.ModuleList()\n",
    "            for conv in range(nb_conv_per_level):\n",
    "                nf = dec_nf[level * nb_conv_per_level + conv]\n",
    "                convs.append(ConvBlock(ndims, prev_nf, nf))\n",
    "                prev_nf = nf\n",
    "            self.decoder.append(convs)\n",
    "            if not half_res or level < (self.nb_levels - 2):\n",
    "                prev_nf += encoder_nfs[level]\n",
    "\n",
    "        # now we take care of any remaining convolutions\n",
    "        self.remaining = nn.ModuleList()\n",
    "        for num, nf in enumerate(final_convs):\n",
    "            self.remaining.append(ConvBlock(ndims, prev_nf, nf))\n",
    "            prev_nf = nf\n",
    "\n",
    "        # cache final number of features\n",
    "        self.final_nf = prev_nf\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # encoder forward pass\n",
    "        x_history = [x]\n",
    "        for level, convs in enumerate(self.encoder):\n",
    "            for conv in convs:\n",
    "                x = conv(x)\n",
    "            x_history.append(x)\n",
    "            x = self.pooling[level](x)\n",
    "\n",
    "        # decoder forward pass with upsampling and concatenation\n",
    "        for level, convs in enumerate(self.decoder):\n",
    "            for conv in convs:\n",
    "                x = conv(x)\n",
    "            if not self.half_res or level < (self.nb_levels - 2):\n",
    "                x = self.upsampling[level](x)\n",
    "                x = torch.cat([x, x_history.pop()], dim=1)\n",
    "\n",
    "        # remaining convs at full resolution\n",
    "        for conv in self.remaining:\n",
    "            x = conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class VxmDense(LoadableModel):\n",
    "    \"\"\"\n",
    "    VoxelMorph network for (unsupervised) nonlinear registration between two images.\n",
    "    \"\"\"\n",
    "\n",
    "    @store_config_args\n",
    "    def __init__(self,\n",
    "                 inshape,\n",
    "                 nb_unet_features=None,\n",
    "                 nb_unet_levels=None,\n",
    "                 unet_feat_mult=1,\n",
    "                 nb_unet_conv_per_level=1,\n",
    "                 int_steps=7,\n",
    "                 int_downsize=2,\n",
    "                 bidir=False,\n",
    "                 use_probs=False,\n",
    "                 src_feats=1,\n",
    "                 trg_feats=1,\n",
    "                 unet_half_res=False):\n",
    "        \"\"\" \n",
    "        Parameters:\n",
    "            inshape: Input shape. e.g. (192, 192, 192)\n",
    "            nb_unet_features: Unet convolutional__init__() got an unexpected keyword argument  features. Can be specified via a list of lists with\n",
    "                the form [[encoder feats], [decoder feats]], or as a single integer. \n",
    "                If None (default), the unet features are defined by the default config described in \n",
    "                the unet class documentation.\n",
    "            nb_unet_levels: Number of levels in unet. Only used when nb_features is an integer. \n",
    "                Default is None.\n",
    "            unet_feat_mult: Per-level feature multiplier. Only used when nb_features is an integer. \n",
    "                Default is 1.\n",
    "            nb_unet_conv_per_level: Number of convolutions per unet level. Default is 1.\n",
    "            int_steps: Number of flow integration steps. The warp is non-diffeomorphic when this \n",
    "                value is 0.\n",
    "            int_downsize: Integer specifying the flow downsample factor for vector integration. \n",
    "                The flow field is not downsampled when this value is 1.\n",
    "            bidir: Enable bidirectional cost function. Default is False.\n",
    "            use_probs: Use probabilities in flow field. Default is False.\n",
    "            src_feats: Number of source image features. Default is 1.\n",
    "            trg_feats: Number of target image features. Default is 1.\n",
    "            unet_half_res: Skip the last unet decoder upsampling. Requires that int_downsize=2. \n",
    "                Default is False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # internal flag indicating whether to return flow or integrated warp during inference\n",
    "        self.training = True\n",
    "\n",
    "        # ensure correct dimensionality\n",
    "        ndims = len(inshape)\n",
    "        assert ndims in [1, 2, 3], 'ndims should be one of 1, 2, or 3. found: %d' % ndims\n",
    "\n",
    "        # configure core unet model\n",
    "        self.unet_model = Unet(\n",
    "            inshape,\n",
    "            infeats=(src_feats + trg_feats),\n",
    "            nb_features=nb_unet_features,\n",
    "            nb_levels=nb_unet_levels,\n",
    "            feat_mult=unet_feat_mult,\n",
    "            nb_conv_per_level=nb_unet_conv_per_level,\n",
    "            half_res=unet_half_res,\n",
    "        )\n",
    "\n",
    "        # configure unet to flow field layer\n",
    "        Conv = getattr(nn, 'Conv%dd' % ndims)\n",
    "        self.flow = Conv(self.unet_model.final_nf, ndims, kernel_size=3, padding=1)\n",
    "\n",
    "        # init flow layer with small weights and bias\n",
    "        self.flow.weight = nn.Parameter(Normal(0, 1e-5).sample(self.flow.weight.shape))\n",
    "        self.flow.bias = nn.Parameter(torch.zeros(self.flow.bias.shape))\n",
    "\n",
    "        # probabilities are not supported in pytorch\n",
    "        if use_probs:\n",
    "            raise NotImplementedError(\n",
    "                'Flow variance has not been implemented in pytorch - set use_probs to False')\n",
    "\n",
    "        # configure optional resize layers (downsize)\n",
    "        if not unet_half_res and int_steps > 0 and int_downsize > 1:\n",
    "            self.resize = layers.ResizeTransform(int_downsize, ndims)\n",
    "        else:\n",
    "            self.resize = None\n",
    "\n",
    "        # resize to full res\n",
    "        if int_steps > 0 and int_downsize > 1:\n",
    "            self.fullsize = layers.ResizeTransform(1 / int_downsize, ndims)\n",
    "        else:\n",
    "            self.fullsize = None\n",
    "\n",
    "        # configure bidirectional training\n",
    "        self.bidir = bidir\n",
    "\n",
    "        # configure optional integration layer for diffeomorphic warp\n",
    "        down_shape = [int(dim / int_downsize) for dim in inshape]\n",
    "        self.integrate = layers.VecInt(down_shape, int_steps) if int_steps > 0 else None\n",
    "\n",
    "        # configure transformer\n",
    "        self.transformer = layers.SpatialTransformer(inshape)\n",
    "\n",
    "    def forward(self, source, target, registration=False):\n",
    "        '''\n",
    "        Parameters:\n",
    "            source: Source image tensor.\n",
    "            target: Target image tensor.\n",
    "            registration: Return transformed image and flow. Default is False.\n",
    "        '''\n",
    "\n",
    "        # concatenate inputs and propagate unet\n",
    "        x = torch.cat([source, target], dim=1)\n",
    "        x = self.unet_model(x)\n",
    "\n",
    "        # transform into flow field\n",
    "        flow_field = self.flow(x)\n",
    "\n",
    "        # resize flow for integration\n",
    "        pos_flow = flow_field\n",
    "        if self.resize:\n",
    "            pos_flow = self.resize(pos_flow)\n",
    "\n",
    "        preint_flow = pos_flow\n",
    "\n",
    "        # negate flow for bidirectional model\n",
    "        neg_flow = -pos_flow if self.bidir else None\n",
    "\n",
    "        # integrate to produce diffeomorphic warp\n",
    "        if self.integrate:\n",
    "            pos_flow = self.integrate(pos_flow)\n",
    "            neg_flow = self.integrate(neg_flow) if self.bidir else None\n",
    "\n",
    "            # resize to final resolution\n",
    "            if self.fullsize:\n",
    "                pos_flow = self.fullsize(pos_flow)\n",
    "                neg_flow = self.fullsize(neg_flow) if self.bidir else None\n",
    "\n",
    "        # warp image with flow field\n",
    "        y_source = self.transformer(source, pos_flow)\n",
    "        y_target = self.transformer(target, neg_flow) if self.bidir else None\n",
    "\n",
    "        # return non-integrated flow field if training\n",
    "        if not registration:\n",
    "            return (y_source, y_target, preint_flow) if self.bidir else (y_source, preint_flow)\n",
    "        else:\n",
    "            return y_source, pos_flow\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Specific convolutional block followed by leakyrelu for unet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ndims, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        Conv = getattr(nn, 'Conv%dd' % ndims) #oh wow c'est hyper malin\n",
    "        self.main = Conv(in_channels, out_channels, 3, stride, 1)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
