from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

from monai.transforms import AddChannel

import numpy as np

#alors comme on appel ce fichier depuis un fichier extérieur, faut repréciser le path d'importation
from Dataloaders.MRI_loader import get_data_dicts, load
from process.utils import to_tensor


"""
Custom Dataset inheriting from Pytorch Dataset
Takes a list of IDs used to load data and associated labels (both generated by get_data_dicts.py)
"""

class Registration_dataset(Dataset):

    def __init__(self, list_IDs, transform=None, vectorize=False):
        self.list_IDs = list_IDs
        self.transform = transform
        self.vectorize=vectorize

    def __len__(self):
        return len(self.list_IDs)
    
    def __getitem__(self, index):
        """
        Main function of the CustomDataset class. 
        Uses utils.load.py to load data. 
        """
        item_id_fixed = self.list_IDs[index]
        item_id_moving = self.list_IDs[np.random.randint(0,len(self.list_IDs))] #we select randomly another image to registrate
        
        #fixed_image, moving_image, fixed_mask, moving_mask = load(item_id_fixed, item_id_moving)
        scanners=list(load(item_id_fixed, item_id_moving, self.vectorize))

        if self.transform is not None:
            
            if self.vectorize:
                for i, scan in enumerate(scanners):
                    if len(scan.shape)>3 :
                        scanners[i]=to_tensor(scan,self.transform)
                    else :
                        scanners[i]=self.transform(scan)
            else :
                for i, scan in enumerate(scanners):
                    scanners[i]=self.transform(scan)

        return scanners
    

"""
Generated two dataloaders for training and validation.
Used utils.get_data_dicts.py to generates the IDs and associated labels in order to instanciate two CustomDatasets.
"""

def get_dataloaders(dataloader_config):
    partition = get_data_dicts(dataloader_config['rootdir'], dataloader_config['valid_ratio'])
    training_set    =   Registration_dataset(partition['train'],
                                             dataloader_config['transformation'],
                                            dataloader_config['vectorize'])
    validation_set  =   Registration_dataset(partition['validation'], 
                                             dataloader_config['transformation'],
                                            dataloader_config['vectorize'])
    training_generator   = DataLoader(training_set,
                                      batch_size=dataloader_config['batch_size'],
                                      shuffle=True)
    validation_generator = DataLoader(validation_set,
                                      batch_size=dataloader_config['batch_size'],
                                      shuffle=False)
    return training_generator, validation_generator
