{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1170cb9c-8737-4b14-a18b-bbd62f350b27",
   "metadata": {},
   "source": [
    "# Vectormorph Projet 3A Résultats\n",
    "Luther OLLIER, Stanislas MARESCHAL DE CHARENTENAY, Herve SILUE\n",
    "<br/>\n",
    "## Sommaire :\n",
    "- Contexte et Problématique\n",
    "- Les Datasets\n",
    "- Training sur les images\n",
    "- Training sur les images transformées\n",
    "- Comparaison des résultats\n",
    "\n",
    "\n",
    "## Contexte et Problématique\n",
    "\n",
    "Le recalage en imagerie médicale est une tâche qui consiste à déterminer une représentation spatiale optimale permettant de\n",
    "superposer le plus exactement deux images (scanner, IRM, TEP, ultrason...).\n",
    "\n",
    "Cependant cette tâche est rendu difficile par :\n",
    "\n",
    "- La variabilité des représentations sous-jacentes (mouvement respiratoire, l’évolution d’une pathologie).\n",
    "\n",
    "- Des difficultés d’acquisition propres à chaque modalité (niveau de bruit important en imagerie ultrasonore, la non-correspondance entre régions fonctionnelles et anatomiques en TEP-scanner).\n",
    "\n",
    "Le recalage de représentation structurelles (transformations particulières conservant l’information sur la structure) des images donne des résultats équivalents, voir plus intéressants dans certains cas, que le recalage d’images brutes.\n",
    "\n",
    "On s'intéresse à une représentation structurelle obtenue par la méthode Vector Field Convolution (VFC). Cette transformation consiste à convoluer un noyau vectoriel avec les contours de l’image. La VFC a pour paramètres (a,r) avec r la taille du kernel et a qui caractérise l’évolution de l’amplitude du champ. \n",
    "\n",
    "Le but de ce projet est d’étudier les performance du framework Voxelmorph, spécialisé en recalage d’image par deep-learning, sur les représentations structurelles par VFC. \n",
    "\n",
    "## Datasets\n",
    "  \n",
    "Le dataset initial était composé de 400 IRM du cerveau et des masques de segmentations associés (indispensable au calcul de la métrique Dice choisie comme métrique de performance). Cependant pour des raisons calculatoires (impossible d'entraîner dans des conditions satisfaisantes des scanners 3D de vecteurs) nous nous sommes rabattus sur un Dataset 2D plus simple, le [HandMnist](https://github.com/Project-MONAI/MONAI/blob/master/examples/notebooks/mednist_tutorial.ipynb) \n",
    "de Monai contenant 10000 radios des mains. Cependant sans masques de segmentations, nous n'avons pas pu évaluer les performances aussi précisément que nous l'aurions voulu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad4f0e-fc30-44a5-b721-708b0f43d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataloaders.MRI_loader import get_labels_list\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dataset_path=''\n",
    "images_path=get_labels_list(dataset_path)\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(20,10))\n",
    "for i in range(10):\n",
    "    image=asarray(Image.open(images_path[i]))\n",
    "    axes[i,i-((i//5)*5)].imshow(slice.T, origin=\"lower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6829ed37-bf04-4dcc-a9e7-e5bae9b8bd6f",
   "metadata": {},
   "source": [
    "Pour effectuer la transformation VFC sur les images nous allons convoluer un noyau vectoriel avec les contours de l'image. Ils sont affichés ci-dessous notamment pour les 2 valeurs de a que nous allons utiliser pour les entrainements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d37d1-9c79-4eae-b41d-dab0c2da0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process.utils import to_vector, image_contour, VFK\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.title(\"Raw image\")\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title(\"Image contour\")\n",
    "plt.imshow(image_contour(fixed_image))\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.title(\"Kernel for a=1.5 and r=10\")\n",
    "K = VFK(a=1.5,r=10)\n",
    "nkx,nky = K.shape\n",
    "xv ,yv = np.meshgrid(range(nkx),range(nky))\n",
    "plt.quiver(xv, yv)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.title(\"Kernel for a=3 and r=10\")\n",
    "K = VFK(a=3,r=10)\n",
    "nkx,nky= K.shape\n",
    "xv ,yv = np.meshgrid(range(nkx),range(nky))\n",
    "plt.quiver(xv, yv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9443949c-48e4-41c3-8bbf-448f350f7798",
   "metadata": {},
   "source": [
    "Affichons maintenant des images vectorisées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc8bfc-af3b-40c9-a7b8-b2efcd0c27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(5, 3, figsize=(20,10))\n",
    "\n",
    "nx,ny = fixed_image.shape\n",
    "xv ,yv = np.meshgrid(range(ny),range(nx))\n",
    "\n",
    "for i in range(5):\n",
    "    image=asarray(Image.open(images_path[i]))\n",
    "    \n",
    "    plt.subplot(5,3,(5*i))\n",
    "    plt.title(\"image\")\n",
    "    plt.imshow(image.T, origin=\"lower\")\n",
    "    \n",
    "    plt.subplot(5,3,(5*(i+1)))\n",
    "    plt.title(\"VFC for a = 1.5\")\n",
    "    vector_field = to_vector(fixed_image,r=10,a=1.5)\n",
    "    plt.quiver(xv,yv,vector_field[:,:,0],vector_field[:,:,1])\n",
    "    \n",
    "    plt.subplot(5,3,(5*(i+2)))\n",
    "    plt.title(\"VFC for a = 3\")\n",
    "    vector_field = to_vector(fixed_image,r=10,a=3)\n",
    "    plt.quiver(xv,yv,vector_field[:,:,0],vector_field[:,:,1])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a1140-79b9-41e9-bd49-3b9261a0c9b5",
   "metadata": {},
   "source": [
    "le coefficient __a__ caractérise l’amplitude du champ vectoriel $k(x,y) =  \\frac{v(x,y)}{(r^(a+1)+\\epsilon)}$, on observe sur les images que les transformations VFC pour a=3 sont caractérisées par un champ vectoriel plus marqué, moins lisse.\n",
    "\n",
    "## Training sur les images\n",
    "\n",
    "Pour une batch size de 32, un dataset d'entrainement de 6000 images et de 4000 pour la validation, voici la courbe d'apprentissage pour 500 epoques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb50d27-49d1-408e-8781-204ddb2b7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process.utils import loss_recovery\n",
    "\n",
    "path_output_2D=\"\"\n",
    "loss_recovery(path_output_2D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6597eb-3b57-4019-a826-104043898d8a",
   "metadata": {},
   "source": [
    "On peut voir que la loss $(MSE+0.05\\Delta(vectorfield))$  converge au bout de ** epoch vers **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d5d0b-4e1b-4828-aed1-4878e99be1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import evaluate\n",
    "from config import model_config, dataloader_config, train_config, criterion_config, scheduler_config\n",
    "model_state_dict_path=\"path\"\n",
    "trained_model = evaluate(model_state_dict_path, model_config, dataloader_config, train_config, criterion_config, scheduler_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29529d3b-e186-4fce-aa83-14d3da545e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading two scan for visualization\n",
    "import torch\n",
    "\n",
    "fixed_image,moving_image=next(iter(trainer.testloader))\n",
    "fixed_image, moving_image = fixed_image.to(trainer.model.device), moving_image.to(trainer.model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "            pred_image, flow_field = trainer.model.net(moving_image.float(),fixed_image.float())\n",
    "            loss = trainer.model.criterion(pred_image, fixed_image, flow_field)\n",
    "            \n",
    "fixed_image,moving_image=fixed_image.detach().cpu().numpy(),moving_image.detach().cpu().numpy()\n",
    "pred_image, flow_field = pred_image.detach().cpu().numpy(), flow_field.detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(fixed_image)\n",
    "plt.title(\"image cible\")\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(moving_image)\n",
    "plt.title(\"image à recaler\")\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(pred_image)\n",
    "plt.title(\"image recalée\")\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.quiver(xv,yv,flow_field[:,:,0],flow_field[:,:,1])\n",
    "plt.title(\"champ de transformation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fe782-7c8a-45db-9edf-3c42d0183510",
   "metadata": {
    "tags": []
   },
   "source": [
    "blabla\n",
    "\n",
    "## Training sur les images transformées\n",
    "\n",
    "Nous avons effectué 2 entrainements, un pour a=1.5 et un autre pour a=3 (amplitude plus forte du champ vectoriel)\n",
    "\n",
    "### a=1.5\n",
    "courbe de loss :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba5769-e2e7-476f-b7ec-4b53759f8a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process.utils import loss_recovery\n",
    "\n",
    "path_output_2D_vec_0=\"\"\n",
    "loss_recovery(path_output_2D_vec_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a6d659-4816-4ad4-9f4e-4aaad0da0b3a",
   "metadata": {},
   "source": [
    "On peut voir que la loss converge au bout de ** epoch vers **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09190bf8-c942-4516-b506-0e5209ac6f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader_config['vectorize']=True\n",
    "dataloader_config['a']=1.5\n",
    "model_config['src_feats']=3\n",
    "model_config['trg_feats']=3\n",
    "model_state_dict_path=\"path\"\n",
    "trained_model = evaluate(model_state_dict_path, model_config, dataloader_config, train_config, criterion_config, scheduler_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e562f-e5b4-48fe-8358-5c5a830208bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading two scan for visualization\n",
    "import torch\n",
    "\n",
    "fixed_image,moving_image=next(iter(trainer.testloader))\n",
    "fixed_image, moving_image = fixed_image.to(trainer.model.device), moving_image.to(trainer.model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "            pred_image, flow_field = trainer.model.net(moving_image.float(),fixed_image.float())\n",
    "            loss = trainer.model.criterion(pred_image, fixed_image, flow_field)\n",
    "            \n",
    "fixed_image,moving_image=fixed_image.detach().cpu().numpy(),moving_image.detach().cpu().numpy()\n",
    "pred_image, flow_field = pred_image.detach().cpu().numpy(), flow_field.detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(fixed_image)\n",
    "plt.title(\"image cible\")\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(moving_image)\n",
    "plt.title(\"image à recaler\")\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(pred_image)\n",
    "plt.title(\"image recalée\")\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.quiver(xv,yv,flow_field[:,:,0],flow_field[:,:,1])\n",
    "plt.title(\"champ de transformation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce044bc-1746-4fe0-80e3-81cf5858b06d",
   "metadata": {},
   "source": [
    "### a=3\n",
    "\n",
    "courbe de loss :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff40fbf-dbff-4a8e-bce5-cb8034be088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process.utils import loss_recovery\n",
    "\n",
    "path_output_2D_vec_1=\"\"\n",
    "loss_recovery(path_output_2D_vec_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd827a55-e049-42d7-8b25-a8bfce77b3f4",
   "metadata": {},
   "source": [
    "On peut voir que la loss converge au bout de ** epoch vers **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c84df79-636f-45da-9e76-1533d360314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_config['a']=3\n",
    "model_state_dict_path=\"path\"\n",
    "trained_model = evaluate(model_state_dict_path, model_config, dataloader_config, train_config, criterion_config, scheduler_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8791736-0035-4913-a548-0b52013e9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading two scan for visualization\n",
    "import torch\n",
    "\n",
    "fixed_image,moving_image=next(iter(trainer.testloader))\n",
    "fixed_image, moving_image = fixed_image.to(trainer.model.device), moving_image.to(trainer.model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "            pred_image, flow_field = trainer.model.net(moving_image.float(),fixed_image.float())\n",
    "            loss = trainer.model.criterion(pred_image, fixed_image, flow_field)\n",
    "            \n",
    "fixed_image,moving_image=fixed_image.detach().cpu().numpy(),moving_image.detach().cpu().numpy()\n",
    "pred_image, flow_field = pred_image.detach().cpu().numpy(), flow_field.detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(fixed_image)\n",
    "plt.title(\"image cible\")\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(moving_image)\n",
    "plt.title(\"image à recaler\")\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(pred_image)\n",
    "plt.title(\"image recalée\")\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.quiver(xv,yv,flow_field[:,:,0],flow_field[:,:,1])\n",
    "plt.title(\"champ de transformation\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
