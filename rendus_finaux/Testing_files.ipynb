{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d8764c-47c9-479b-aab4-f8acd5069059",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing notebook\n",
    "<br/>\n",
    "it aims to unit test each files and functions and provide a good tuto of the code.\n",
    "<br/>  \n",
    "<br/>\n",
    "For each files the config.py contains a dictionnary to modify the parameters\n",
    "\n",
    "### Overview :   \n",
    "- Dataloaders/ : Loading data + transformations :\n",
    "    - MRI_loader.py \n",
    "    - registration_loader.py\n",
    "- process/ : \n",
    "    - losses.py\n",
    "    - utils.py\n",
    "- Model.py\n",
    "- Trainer.py\n",
    "- main.py\n",
    "\n",
    "\n",
    "<br/>   \n",
    " \n",
    "### Dataloaders/ : Loading data + transformations :\n",
    "To upload the data, add transformations and create validation and training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a0c076-b85f-43f1-af09-1408dc71d0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rootdir': 'Documents/Projet_3A/data/2D_data/MedNIST/Hand/',\n",
       " 'batch_size': 1,\n",
       " 'valid_ratio': 0.2,\n",
       " 'num_workers': 1,\n",
       " 'transformation': Compose(\n",
       "     ToTensor()\n",
       "     <monai.transforms.utility.array.AddChannel object at 0x7f10127d81c0>\n",
       " ),\n",
       " 'vectorize': False}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import dataloader_config\n",
    "dataloader_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a5ea13-937f-4cdd-bf7a-c24055487e53",
   "metadata": {},
   "source": [
    "- rootdir : the root of the folder containing the data\n",
    "- batch_size \n",
    "- valid_ratio : the proportion of validation data you want to include\n",
    "- num_workers : in case of calcul parallelisation \n",
    "- transformation : sequence of torch or monai transformations to apply to the data (rotations, normalize etc..)\n",
    "note that for 3D vectorized data you absolutely need to use the monai transformations AddChannel\n",
    "- vectorize : wheter to vectorize or not the data\n",
    "<br/>\n",
    "\n",
    "#### MRI_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b24e06-c370-420d-83bc-afe7067229da",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Documents/Projet_3A/data/2D_data/MedNIST/Hand/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4623/2180049919.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mDataloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMRI_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_labels_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_labels_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rootdir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Projet_3A/VectorMorph/src/Dataloaders/MRI_loader.py\u001b[0m in \u001b[0;36mget_labels_list\u001b[0;34m(dataset_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mroot\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mMRI\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0mwe\u001b[0m \u001b[0muse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LICENSE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Documents/Projet_3A/data/2D_data/MedNIST/Hand/'"
     ]
    }
   ],
   "source": [
    "from Dataloaders.MRI_loader import get_labels_list\n",
    "print(get_labels_list(dataloader_config['rootdir']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0da557-5f60-4e87-a5c9-95c5b587293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 \n",
      " 8 \n",
      " /home/luther/Documents/Projet_3A/data/L2R_2021_Task3_test/mask/OASIS_OAS1_0018_MR1\n"
     ]
    }
   ],
   "source": [
    "from Dataloaders.MRI_loader import get_data_dicts\n",
    "\n",
    "partition=get_data_dicts(dataloader_config['rootdir'],dataloader_config['valid_ratio'])\n",
    "print(len(partition['train']),'\\n',len(partition['validation']),'\\n',partition['train'][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c1df1-d53c-4396-bcaa-1364991ed86b",
   "metadata": {},
   "source": [
    "load.py is the file you want to update for differents dataset : take two path as inputs (one for the folder with the fixed image and its segmentation and one for the folder with the moving image and its segmentation), according to your dataset type you might want to modify how the data is load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2154457b-5a3b-47a5-b8d7-493bd3d7df99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 192, 224)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Dataloaders.MRI_loader import load\n",
    "\n",
    "fixed_image,moving_image,fixed_mask,moving_mask=load(partition['train'][0],partition['train'][1],vectorize=False)\n",
    "fixed_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1107f6ea-04f8-4c9f-b931-a0a0d8764e00",
   "metadata": {
    "tags": []
   },
   "source": [
    "We also can see above if to_vector from process.utils works\n",
    "### registration_loader\n",
    "<br/>\n",
    "Use the function from MRI_loader.py to create custom pytorch dataset and dataloaders\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e7bcac-985f-429a-ac6b-a74964883df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224, 160, 192])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Dataloaders.registration_loader import Registration_dataset\n",
    "from torchvision import transforms\n",
    "from monai.transforms import AddChannel\n",
    "\n",
    "\n",
    "t = transforms.Compose([transforms.ToTensor(), AddChannel()])\n",
    "            \n",
    "dataset=Registration_dataset(partition['train'], t, vectorize=False)\n",
    "fixed_image, moving_image, fixed_mask, moving_mask=dataset[2]\n",
    "fixed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c624b9cc-cb75-41f3-bc46-06df93c49675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224, 160, 192])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Dataloaders.registration_loader import get_dataloaders\n",
    "training_generator, validation_generator=get_dataloaders(dataloader_config)\n",
    "next(iter(training_generator))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d953c1d-6473-4b99-82a9-8bb25ca1140d",
   "metadata": {
    "tags": []
   },
   "source": [
    "La fonction addchannel de monai permet d'ajouter la dimension channel sans faire un .view dans le training pour des données 3D (inutile pour des données 2D).\n",
    "<br/>\n",
    "\n",
    "### Process\n",
    "\n",
    "#### Utils\n",
    "utils.py contained a bunch of functions : graphic one, vectorization (with the transformations from the paper) etc.. Only the to_vector is test here (refer to the result notebook or utils.py to learn more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a5ae03-adce-492f-80c9-54f3266258bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 192, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from process.utils import to_vector\n",
    "#Currently 2D data but with 3D how would it works ?\n",
    "fixed_image,moving_image,fixed_mask,moving_mask=load(partition['train'][0],partition['train'][1])\n",
    "to_vector(fixed_image).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac012d95-98fe-44f5-b53b-b06f602366d9",
   "metadata": {},
   "source": [
    "### Losses \n",
    "<br/>\n",
    "\n",
    "#### compute dice test\n",
    "Dice is a metric between two segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0098f5ea-791b-4593-9e68-c2862de250d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4990, 0.6892, 0.6315, 0.3801]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from process.losses import compute_dice\n",
    "\n",
    "#let's compare 2 mask from two random image of our dataset\n",
    "fixed_image,moving_image,fixed_mask,moving_mask=next(iter(training_generator))\n",
    "compute_dice(fixed_mask, moving_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd8acf-e3d8-46a7-9efe-e675beb3f0b0",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27527df6-02e3-4575-8682-ace4e4c57e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0042, dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from process.losses import MSE\n",
    "\n",
    "#let's compare 2 images from dataset\n",
    "MSE(fixed_image, moving_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fcf376-3b8e-4ba8-bbf3-cac4769f82ec",
   "metadata": {},
   "source": [
    "Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0a956c-dd2c-498b-99e8-74edb300753a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7267)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from process.losses import Grad\n",
    "import torch\n",
    "\n",
    "flow_field_random=torch.abs(torch.randn([1,3,160,192,224])) \n",
    "Grad('l2').loss(flow_field_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc40b7bd-6ca7-4077-ac7b-4d769657d651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 1, 'Grad': {'Norm': 'l2', 'weight': 0.05}, 'Dice': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import criterion_config\n",
    "criterion_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03800831-96a8-41ba-9a1f-517bd68372dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "criterion_config is used to configure the model loss (through the Model.py file)\n",
    "- MSE : the weight of MSE in the loss \n",
    "- Grad : 'l2' or 'l1' penalization + the weight in the loss\n",
    "- Dice : Dice is compute anyway but you can add it to the loss or not by putting a weight instead of None\n",
    "### Model\n",
    "\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f6c1374-b3f7-4e77-a87f-79efaad60727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inshape': (224, 160, 192),\n",
       " 'nb_unet_features': [[16, 32, 32], [32, 16, 16]],\n",
       " 'src_feats': 1,\n",
       " 'trg_feats': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import model_config\n",
    "model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0127fd47-b67b-4806-9edd-73648754391f",
   "metadata": {},
   "source": [
    "- inshape : the data input shape (2D or 3D)\n",
    "- nb_unet_features : the size of the encoder layers and of the decoder layers\n",
    "- src_feats/trg_feats : as you might have read in the vxm tuto, theses features handles the number of inputs channel (refer to the end of the vxm tuto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d54bf9-41d8-4baf-8fd7-7941e2d734ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scheduler': 'ROP',\n",
       " 'mode': 'min',\n",
       " 'factor': 0.2,\n",
       " 'patience': 10,\n",
       " 'threshold': 1e-05,\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import scheduler_config\n",
    "scheduler_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0278a13-7684-45fc-8819-d4a09916ccd5",
   "metadata": {},
   "source": [
    "A loss scheduler is implemented (aims to reduce the loss when its not decreasing for a time)\n",
    "- scheduler : type of scheduler, only Reduce On Plateau is implemented\n",
    "- mode : decreasing\n",
    "- factor : new_loss=factor x loss\n",
    "- patience : decrease loss if its not decreasing for 10 epochs\n",
    "- treshold : decrease treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe64d86-0843-4c09-acd6-ec0a3079a8a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VxmDense(\n",
       "  (unet_model): Unet(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (downarm): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (main): Conv3d(2, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (main): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (2): ConvBlock(\n",
       "        (main): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (3): ConvBlock(\n",
       "        (main): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (uparm): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (main): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (main): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (2): ConvBlock(\n",
       "        (main): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (3): ConvBlock(\n",
       "        (main): Conv3d(48, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (extras): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (main): Conv3d(34, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (main): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (2): ConvBlock(\n",
       "        (main): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (flow): Conv3d(16, 3, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (integrate): VecInt(\n",
       "    (transformer): SpatialTransformer()\n",
       "  )\n",
       "  (transformer): SpatialTransformer()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model initialization\n",
    "from Model import model\n",
    "from config import model_config, criterion_config\n",
    "\n",
    "test_model=model(model_config, criterion_config)\n",
    "test_model.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5c72a-f544-4576-9342-8909fb36ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model forward\n",
    "fixed_image,moving_image=fixed_image.to(test_model.device),moving_image.to(test_model.device)\n",
    "pred_image,flow_field=test_model.net(moving_image.float(), fixed_image.float())\n",
    "pred_image.shape,flow_field.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "575c765f-42a9-4f66-be23-49e941c84c9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flow_field' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12130/1562786527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model interpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmoving_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmoving_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoving_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_field\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flow_field' is not defined"
     ]
    }
   ],
   "source": [
    "#model interpolation\n",
    "moving_mask=moving_mask.to(test_model.device)\n",
    "pred_mask = test_model.net.transformer(moving_mask.float(), flow_field)\n",
    "pred_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fc93bf4-0139-4046-aa3e-da753392032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0436, dtype=torch.float64) tensor([0.5087, 0.7257, 0.7022, 0.3913])\n"
     ]
    }
   ],
   "source": [
    "#model criterion\n",
    "import torch\n",
    "flow_field_random=torch.abs(torch.randn([1,3,160,192,224])) \n",
    "loss, train_mean_dice = test_model.criterion(moving_image, moving_mask, fixed_image, fixed_mask, flow_field_random)\n",
    "print(loss, train_mean_dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf7f0f2-a02b-467f-a5de-9ce258e7984a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a4d6e0-7265-4d13-a26f-e6731da25c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nb_epochs': 1000,\n",
       " 'checkpoints_path': 'Documents/Projet_3A/VectorMorph/models/',\n",
       " 'verbose': True,\n",
       " 'checkpoint': 50}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import train_config\n",
    "train_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650de9fc-6e8e-4eba-bb96-37adf5553a42",
   "metadata": {},
   "source": [
    "- nb_epochs : number of training epoch\n",
    "- checkpoints_path : path where saving the training weights\n",
    "- checkpoint : how much epoch to wait for saving weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d12cde-1b56-4ecb-a96d-562b9235bb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f21f929a400>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import load, save \n",
    "from Model import model\n",
    "from Trainer import Trainer\n",
    "from config import model_config, dataloader_config, train_config\n",
    "\n",
    "model = model(model_config)\n",
    "trainer = Trainer(model, dataloader_config, train_config)\n",
    "trainer.trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9496922a-1a5b-4c23-8b2d-6f359cc67f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 28/28 [00:02<00:00, 11.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20536147917010963, tensor(2.2776))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e992d6-0fc8-47a2-bd04-faba76ef854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 33.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.07549482911870577, tensor(2.1523))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c237788-c969-4c39-b608-7870a7225586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss................: 0.00\n",
      "Test Loss.................: 0.00\n",
      "Train Mean Dice............: 0.00\n",
      "Test Mean Dice.............: 0.00\n",
      "\n",
      "Best Test Mean Dice........: 0.00\n"
     ]
    }
   ],
   "source": [
    "trainer.verbose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df4ee3b-47e7-4459-b582-e05a463fad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 28/28 [00:02<00:00, 12.19it/s]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 19.76it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.update_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd2c498-1294-49e1-a5d2-956667f00a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss................: 0.19\n",
      "Test Loss.................: 0.07\n",
      "Train Mean Dice............: 0.00\n",
      "Test Mean Dice.............: 0.00\n",
      "\n",
      "Best Test Mean Dice........: 2.81\n"
     ]
    }
   ],
   "source": [
    "trainer.verbose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf1c93-a545-461b-aa08-826a4b854ea4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Main.py\n",
    "test with only 3 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ce7b5-9a21-4691-a649-5652d542b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config['nb_epochs']=3\n",
    "from main import main, evaluate\n",
    "main(model_config, dataloader_config, train_config, criterion_config, scheduler_config) #can be launch directly from a terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13c361-2d63-4a42-994c-f693a106450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(train_config['checkpoints_path']+'', model_config, dataloader_config, train_config, criterion_config, scheduler_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
